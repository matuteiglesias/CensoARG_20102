{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training ML algos on EPH. Predicting on CENSO."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load modules\n",
    "# import time\n",
    "# time.sleep(2000)\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# Column names\n",
    "y_cols = ['CAT_OCUP', 'P47T', 'PP10E', 'PP10D', 'PP07K', 'PP07I', 'V3_M', 'PP07G4', 'CH16', 'T_VI', \n",
    "          'V12_M', 'TOT_P12', 'PP07G3', 'V5_M', 'PP07H', 'V2_M', 'PP10C', \n",
    "          'PP08D1', 'PP07J', 'CAT_INAC', 'CH07', 'CH08', 'P21', 'PP07G1', 'PP07G_59', 'PP07G2']\n",
    "\n",
    "\n",
    "x_cols = ['IX_TOT', 'P02', 'P03', 'AGLOMERADO', 'V01', 'H05', 'H06',\n",
    "       'H07', 'H08', 'H09', 'H10', 'H11', 'H12', 'H16', 'H15', 'PROP', 'H14',\n",
    "       'H13', 'P07', 'P08', 'P09', 'P10', 'P05', 'CONDACT']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Deflactar nos va a permitir poolear data de todos los trimestres sabiendo que los ingresos anotados son comparables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Q</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2016-06-30</th>\n",
       "      <td>750.674316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-09-30</th>\n",
       "      <td>790.754008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-12-31</th>\n",
       "      <td>832.911987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-03-31</th>\n",
       "      <td>880.007324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-06-30</th>\n",
       "      <td>925.399658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-09-30</th>\n",
       "      <td>971.206665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-12-31</th>\n",
       "      <td>1020.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-03-31</th>\n",
       "      <td>1073.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-06-30</th>\n",
       "      <td>1150.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-09-30</th>\n",
       "      <td>1306.666667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  index\n",
       "Q                      \n",
       "2016-06-30   750.674316\n",
       "2016-09-30   790.754008\n",
       "2016-12-31   832.911987\n",
       "2017-03-31   880.007324\n",
       "2017-06-30   925.399658\n",
       "2017-09-30   971.206665\n",
       "2017-12-31  1020.000000\n",
       "2018-03-31  1073.333333\n",
       "2018-06-30  1150.000000\n",
       "2018-09-30  1306.666667"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indice_precios = pd.read_csv('./../EPH/indice_pricestats_YQ.csv', index_col=0)\n",
    "indice_precios.index = pd.DatetimeIndex(indice_precios.index)\n",
    "indice_precios.index.name = 'Q'\n",
    "indice_precios"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ahora si!\n",
    "## Train on Quarterly data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "# import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Census\n",
    "# file_ = './../../Desktop/extracted_/sample_censo_table_f.1BA.csv'\n",
    "file_ = 'sintetico_2017.1.csv'\n",
    "\n",
    "X_censo = pd.read_csv(file_, usecols = ['DPTO','RADIO_REF_ID','PERSONA_REF_ID','IX_TOT', 'P02', 'P03', 'CONDACT', 'AGLOMERADO', 'V01', 'H05', 'H06',\n",
    "       'H07', 'H08', 'H09', 'H10', 'H11', 'H12', 'H16', 'H15', 'PROP', 'H14',\n",
    "       'H13', 'P07', 'P08', 'P09', 'P10', 'P05', 'circuito', 'dpto_merge']).fillna(0).sample(frac = .1)\n",
    "X_censo[x_cols].values.shape\n",
    "\n",
    "X_censo['P03'] = (abs(X_censo[['P03']] -19) < 3).astype(int) * X_censo[['P03']] + \\\n",
    "(abs(X_censo[['P03']] -19) >= 3).astype(int) * np.floor(10*X_censo[['P03']].rank(pct = 1)-0.01).astype(int)\n",
    "X_censo['CONDACT'] = 100*X_censo['CONDACT']\n",
    "X_censo['AGLOMERADO'] = 10*X_censo['AGLOMERADO']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(152789, 29)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_censo.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load EPH\n",
    "\n",
    "PBA_train = pd.read_csv('./../../Desktop/extracted_/PBA_train.csv').fillna(0)\n",
    "PBA_train['P03'] = (abs(PBA_train[['P03']] -19) < 3).astype(int) * PBA_train[['P03']] + \\\n",
    "(abs(PBA_train[['P03']] -19) >= 3).astype(int) * np.floor(10*PBA_train[['P03']].rank(pct = 1)-0.01).astype(int)\n",
    "PBA_train['CONDACT'] = 100*PBA_train['CONDACT']\n",
    "PBA_train['AGLOMERADO'] = 10*PBA_train['AGLOMERADO']\n",
    "\n",
    "# PBA_train = PBA_train.loc[PBA_train.AGLOMERADO.isin(X_censo['AGLOMERADO'].unique())]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(362218, 46)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PBA_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "### STEP 1\n",
    "x_cols1 = x_cols\n",
    "\n",
    "#     predecir = ['CAT_OCUP', 'CAT_INAC', 'CH07']\n",
    "predecir1 = ['CAT_OCUP', 'CAT_INAC', 'CH07']\n",
    "y_cols1 = predecir1\n",
    "\n",
    "X = PBA_train[x_cols1]\n",
    "y = PBA_train[y_cols1].loc[X.index]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.05)\n",
    "# Rewrite Census data as 'test' set.\n",
    "\n",
    "X = X_train; y = y_train\n",
    "\n",
    "# clf = tree.DecisionTreeClassifier()\n",
    "clf1 = RandomForestClassifier(n_estimators=50)\n",
    "clf1 = clf1.fit(X.values, y.values)\n",
    "\n",
    "y_out1 = clf1.predict(X_censo[x_cols1].values)\n",
    "y_censo_fit1 = pd.DataFrame(y_out1, index = X_censo.index, columns=predecir1)\n",
    "Xy1_censo = pd.concat([X_censo, y_censo_fit1], axis = 1)\n",
    "\n",
    "### STEP 2\n",
    "\n",
    "x_cols2 = x_cols1+predecir1\n",
    "# La seccion PP07G pregunta si el trabajo es en blanco y que beneficios tiene. Puede ayudar a la regresion para ingresos.\n",
    "predecir2 = ['PP07G1', 'PP07G2', 'PP07G3', 'PP07G4', 'PP07G_59', 'PP07H', 'PP07I', 'PP07J', 'PP07K']\n",
    "y_cols2 = predecir2\n",
    "X = PBA_train[x_cols2]\n",
    "y = PBA_train[y_cols2].loc[X.index]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.05)\n",
    "X = X_train; y = y_train\n",
    "\n",
    "# clf2 = tree.DecisionTreeClassifier()\n",
    "# clf2 = clf2.fit(X.values, y.values)\n",
    "clf2 = RandomForestClassifier(n_estimators=50).fit(X.values, y.values)\n",
    "\n",
    "y_out2 = clf2.predict(Xy1_censo[x_cols2].values)\n",
    "y_censo_fit2 = pd.DataFrame(y_out2, index = X_censo.index, columns=predecir2)\n",
    "Xy2_censo = pd.concat([Xy1_censo, y_censo_fit2], axis = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # save RFC_25rand_20162\n",
    "# Xy2_censo.to_csv('sintetico_circus_condact.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.read_csv('./../../Desktop/extracted_/PBA_train.csv').fillna(0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.read_csv('./../../Desktop/extracted_/PBA_train_'+T+'.csv').fillna(0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 362218/65126"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20162\n",
      "20163\n",
      "20164\n",
      "20171\n",
      "20172\n",
      "20173\n",
      "20174\n",
      "20181\n",
      "20182\n",
      "20183\n",
      "(813332, 48)"
     ]
    }
   ],
   "source": [
    "# Lo que voy a hacer es escalar las columnas de PBA Train segun indice de precios...\n",
    "PBA_train_Tlist = []\n",
    "\n",
    "for T in ['20162', '20163', '20164', '20171', '20172',  '20173',  '20174',  '20181', '20182', '20183']:\n",
    "    print(T)\n",
    "    ### STEP 3 (Regression)\n",
    "    PBA_train_Tlist += [pd.read_csv('./../../Desktop/extracted_/PBA_train_'+T+'.csv').fillna(0)]\n",
    "\n",
    "print(pd.concat(PBA_train_Tlist).shape)\n",
    "PBA_train = pd.concat(PBA_train_Tlist).reset_index(drop = True)\n",
    "\n",
    "columnas_en_pesos_corr = ['P47T']#, 'V3_M', 'T_VI', 'V12_M', 'TOT_P12', 'V5_M','V2_M', 'PP08D1', 'P21']\n",
    "\n",
    "df = PBA_train[['ANO4', 'TRIMESTRE']+columnas_en_pesos_corr]\n",
    "df['Q'] = df['ANO4'].astype(str)+'-'+(3*df['TRIMESTRE']).astype(str).str.zfill(2)\n",
    "df['Q'] = pd.to_datetime(df['Q']) + pd.offsets.MonthEnd(0)\n",
    "\n",
    "df = df.merge(indice_precios.reset_index())\n",
    "\n",
    "PBA_train[columnas_en_pesos_corr] = PBA_train[columnas_en_pesos_corr].div(df['index'].values, 0)\n",
    "\n",
    "PBA_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for T in ['20162', '20163', '20164', '20171', '20172',  '20173',  '20174',  '20181', '20182', '20183']:\n",
    "#     print(T)\n",
    "#     ### STEP 3 (Regression)\n",
    "#     PBA_train = pd.read_csv('./../../Desktop/extracted_/PBA_train_'+T+'.csv').fillna(0)\n",
    "\n",
    "x_cols3 = x_cols2 + predecir2\n",
    "# Columnas de ingresos. Necesitan una regresion...\n",
    "predecir3 = columnas_en_pesos_corr\n",
    "y_cols3 = predecir3\n",
    "\n",
    "X = PBA_train[x_cols3]#.sample(frac = 1) #PBA_train_reg\n",
    "y = PBA_train[y_cols3].loc[X.index] #PBA_train_reg\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "X = X_train; y = y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 500\n",
    "clf3 = RandomForestRegressor(n_estimators=50)\n",
    "clf3 = clf3.fit(X.head(n).values, y.head(n).values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_out3 = clf3.predict(Xy2_censo[x_cols3].values)\n",
    "y_censo_fit3 = pd.DataFrame(y_out3, index = X_censo.index, columns=predecir3)\n",
    "Xy3_censo = pd.concat([Xy2_censo, y_censo_fit3], axis = 1)\n",
    "# Xy3_censo['ANO4'] = T[:-1]; Xy3_censo['TRIMESTRE'] = T[-1]\n",
    "\n",
    "\n",
    "# save\n",
    "#     Xy3_censo.to_csv('RFReg_.01AR'+T+'.csv', index = False)\n",
    "Xy3_censo.to_csv('sintetico_circus_income_YQ_deflac.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X.count()!=len(X)).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.fillna(0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PBA_train[y_cols3].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PBA_train[x_cols3].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
